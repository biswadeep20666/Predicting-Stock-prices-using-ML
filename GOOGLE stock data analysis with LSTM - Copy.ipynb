{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "import math, time\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from operator import itemgetter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "import h5py\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "      <th>adj close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>123.430000</td>\n",
       "      <td>122.309998</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>2163600.0</td>\n",
       "      <td>125.839996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>125.239998</td>\n",
       "      <td>119.940002</td>\n",
       "      <td>125.540001</td>\n",
       "      <td>2386400.0</td>\n",
       "      <td>119.980003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>116.379997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>119.739998</td>\n",
       "      <td>2489500.0</td>\n",
       "      <td>114.949997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-08</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>115.480003</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>117.440002</td>\n",
       "      <td>2006300.0</td>\n",
       "      <td>116.620003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>117.010002</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>117.330002</td>\n",
       "      <td>1408600.0</td>\n",
       "      <td>114.970001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           symbol        open         low        high     volume   adj close\n",
       "date                                                                        \n",
       "2016-01-05   WLTW  123.430000  122.309998  126.250000  2163600.0  125.839996\n",
       "2016-01-06   WLTW  125.239998  119.940002  125.540001  2386400.0  119.980003\n",
       "2016-01-07   WLTW  116.379997  114.930000  119.739998  2489500.0  114.949997\n",
       "2016-01-08   WLTW  115.480003  113.500000  117.440002  2006300.0  116.620003\n",
       "2016-01-11   WLTW  117.010002  114.089996  117.330002  1408600.0  114.970001"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"prices-split-adjusted.csv\", index_col = 0)\n",
    "df[\"adj close\"] = df.close # Moving close to the last column\n",
    "df.drop(['close'], 1, inplace=True) # Moving close to the last column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Ticker Symbol</th>\n",
       "      <th>Period Ending</th>\n",
       "      <th>Accounts Payable</th>\n",
       "      <th>Accounts Receivable</th>\n",
       "      <th>Add'l income/expense items</th>\n",
       "      <th>After Tax ROE</th>\n",
       "      <th>Capital Expenditures</th>\n",
       "      <th>Capital Surplus</th>\n",
       "      <th>Cash Ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>Total Current Assets</th>\n",
       "      <th>Total Current Liabilities</th>\n",
       "      <th>Total Equity</th>\n",
       "      <th>Total Liabilities</th>\n",
       "      <th>Total Liabilities &amp; Equity</th>\n",
       "      <th>Total Revenue</th>\n",
       "      <th>Treasury Stock</th>\n",
       "      <th>For Year</th>\n",
       "      <th>Earnings Per Share</th>\n",
       "      <th>Estimated Shares Outstanding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>3.068000e+09</td>\n",
       "      <td>-222000000.0</td>\n",
       "      <td>-1.961000e+09</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-1.888000e+09</td>\n",
       "      <td>4.695000e+09</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.072000e+09</td>\n",
       "      <td>9.011000e+09</td>\n",
       "      <td>-7.987000e+09</td>\n",
       "      <td>2.489100e+10</td>\n",
       "      <td>1.690400e+10</td>\n",
       "      <td>2.485500e+10</td>\n",
       "      <td>-367000000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>-5.60</td>\n",
       "      <td>3.350000e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>4.975000e+09</td>\n",
       "      <td>-93000000.0</td>\n",
       "      <td>-2.723000e+09</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-3.114000e+09</td>\n",
       "      <td>1.059200e+10</td>\n",
       "      <td>75.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.432300e+10</td>\n",
       "      <td>1.380600e+10</td>\n",
       "      <td>-2.731000e+09</td>\n",
       "      <td>4.500900e+10</td>\n",
       "      <td>4.227800e+10</td>\n",
       "      <td>2.674300e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>-11.25</td>\n",
       "      <td>1.630222e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>4.668000e+09</td>\n",
       "      <td>-160000000.0</td>\n",
       "      <td>-1.500000e+08</td>\n",
       "      <td>143.0</td>\n",
       "      <td>-5.311000e+09</td>\n",
       "      <td>1.513500e+10</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.175000e+10</td>\n",
       "      <td>1.340400e+10</td>\n",
       "      <td>2.021000e+09</td>\n",
       "      <td>4.120400e+10</td>\n",
       "      <td>4.322500e+10</td>\n",
       "      <td>4.265000e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>4.02</td>\n",
       "      <td>7.169154e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>5.102000e+09</td>\n",
       "      <td>352000000.0</td>\n",
       "      <td>-7.080000e+08</td>\n",
       "      <td>135.0</td>\n",
       "      <td>-6.151000e+09</td>\n",
       "      <td>1.159100e+10</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.985000e+09</td>\n",
       "      <td>1.360500e+10</td>\n",
       "      <td>5.635000e+09</td>\n",
       "      <td>4.278000e+10</td>\n",
       "      <td>4.841500e+10</td>\n",
       "      <td>4.099000e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>11.39</td>\n",
       "      <td>6.681299e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AAP</td>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>2.409453e+09</td>\n",
       "      <td>-89482000.0</td>\n",
       "      <td>6.000000e+05</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-2.711820e+08</td>\n",
       "      <td>5.202150e+08</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.184200e+09</td>\n",
       "      <td>2.559638e+09</td>\n",
       "      <td>1.210694e+09</td>\n",
       "      <td>3.403120e+09</td>\n",
       "      <td>4.613814e+09</td>\n",
       "      <td>6.205003e+09</td>\n",
       "      <td>-27095000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5.29</td>\n",
       "      <td>7.328355e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Ticker Symbol Period Ending  Accounts Payable  \\\n",
       "0           0           AAL    2012-12-31      3.068000e+09   \n",
       "1           1           AAL    2013-12-31      4.975000e+09   \n",
       "2           2           AAL    2014-12-31      4.668000e+09   \n",
       "3           3           AAL    2015-12-31      5.102000e+09   \n",
       "4           4           AAP    2012-12-29      2.409453e+09   \n",
       "\n",
       "   Accounts Receivable  Add'l income/expense items  After Tax ROE  \\\n",
       "0         -222000000.0               -1.961000e+09           23.0   \n",
       "1          -93000000.0               -2.723000e+09           67.0   \n",
       "2         -160000000.0               -1.500000e+08          143.0   \n",
       "3          352000000.0               -7.080000e+08          135.0   \n",
       "4          -89482000.0                6.000000e+05           32.0   \n",
       "\n",
       "   Capital Expenditures  Capital Surplus  Cash Ratio  \\\n",
       "0         -1.888000e+09     4.695000e+09        53.0   \n",
       "1         -3.114000e+09     1.059200e+10        75.0   \n",
       "2         -5.311000e+09     1.513500e+10        60.0   \n",
       "3         -6.151000e+09     1.159100e+10        51.0   \n",
       "4         -2.711820e+08     5.202150e+08        23.0   \n",
       "\n",
       "               ...               Total Current Assets  \\\n",
       "0              ...                       7.072000e+09   \n",
       "1              ...                       1.432300e+10   \n",
       "2              ...                       1.175000e+10   \n",
       "3              ...                       9.985000e+09   \n",
       "4              ...                       3.184200e+09   \n",
       "\n",
       "   Total Current Liabilities  Total Equity  Total Liabilities  \\\n",
       "0               9.011000e+09 -7.987000e+09       2.489100e+10   \n",
       "1               1.380600e+10 -2.731000e+09       4.500900e+10   \n",
       "2               1.340400e+10  2.021000e+09       4.120400e+10   \n",
       "3               1.360500e+10  5.635000e+09       4.278000e+10   \n",
       "4               2.559638e+09  1.210694e+09       3.403120e+09   \n",
       "\n",
       "   Total Liabilities & Equity  Total Revenue  Treasury Stock  For Year  \\\n",
       "0                1.690400e+10   2.485500e+10    -367000000.0    2012.0   \n",
       "1                4.227800e+10   2.674300e+10             0.0    2013.0   \n",
       "2                4.322500e+10   4.265000e+10             0.0    2014.0   \n",
       "3                4.841500e+10   4.099000e+10             0.0    2015.0   \n",
       "4                4.613814e+09   6.205003e+09     -27095000.0    2012.0   \n",
       "\n",
       "   Earnings Per Share  Estimated Shares Outstanding  \n",
       "0               -5.60                  3.350000e+08  \n",
       "1              -11.25                  1.630222e+08  \n",
       "2                4.02                  7.169154e+08  \n",
       "3               11.39                  6.681299e+08  \n",
       "4                5.29                  7.328355e+07  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"fundamentals.csv\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract all symbols from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols = list(set(df.symbol))\n",
    "len(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BLL',\n",
       " 'SWN',\n",
       " 'DD',\n",
       " 'PEP',\n",
       " 'A',\n",
       " 'AZO',\n",
       " 'CSX',\n",
       " 'BSX',\n",
       " 'CCL',\n",
       " 'UNH',\n",
       " 'UAA',\n",
       " 'APC',\n",
       " 'DOV',\n",
       " 'MAC',\n",
       " 'MCK']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols[:15] # Example of what is in symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract a particular price for stock in symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "      <th>adj close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>312.304948</td>\n",
       "      <td>310.955001</td>\n",
       "      <td>313.580158</td>\n",
       "      <td>3927000.0</td>\n",
       "      <td>312.205308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>312.419511</td>\n",
       "      <td>309.610028</td>\n",
       "      <td>312.748278</td>\n",
       "      <td>6031900.0</td>\n",
       "      <td>310.830459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>311.761979</td>\n",
       "      <td>302.048370</td>\n",
       "      <td>311.761979</td>\n",
       "      <td>7987100.0</td>\n",
       "      <td>302.994813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>303.562685</td>\n",
       "      <td>295.218951</td>\n",
       "      <td>303.861575</td>\n",
       "      <td>12876600.0</td>\n",
       "      <td>295.941242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>294.895159</td>\n",
       "      <td>293.455551</td>\n",
       "      <td>300.499172</td>\n",
       "      <td>9483900.0</td>\n",
       "      <td>299.886470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  open         low        high      volume   adj close\n",
       "date                                                                  \n",
       "2010-01-04  312.304948  310.955001  313.580158   3927000.0  312.205308\n",
       "2010-01-05  312.419511  309.610028  312.748278   6031900.0  310.830459\n",
       "2010-01-06  311.761979  302.048370  311.761979   7987100.0  302.994813\n",
       "2010-01-07  303.562685  295.218951  303.861575  12876600.0  295.941242\n",
       "2010-01-08  294.895159  293.455551  300.499172   9483900.0  299.886470"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.symbol == 'GOOG']\n",
    "df.drop(['symbol'],1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "      <th>adj close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>0.157047</td>\n",
       "      <td>0.161167</td>\n",
       "      <td>0.156390</td>\n",
       "      <td>0.131722</td>\n",
       "      <td>0.159399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>0.157238</td>\n",
       "      <td>0.158884</td>\n",
       "      <td>0.154995</td>\n",
       "      <td>0.202469</td>\n",
       "      <td>0.157092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>0.156140</td>\n",
       "      <td>0.146049</td>\n",
       "      <td>0.153341</td>\n",
       "      <td>0.268184</td>\n",
       "      <td>0.143942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>0.142436</td>\n",
       "      <td>0.134457</td>\n",
       "      <td>0.140094</td>\n",
       "      <td>0.432522</td>\n",
       "      <td>0.132105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>0.127950</td>\n",
       "      <td>0.131464</td>\n",
       "      <td>0.134455</td>\n",
       "      <td>0.318492</td>\n",
       "      <td>0.138726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                open       low      high    volume  adj close\n",
       "date                                                         \n",
       "2010-01-04  0.157047  0.161167  0.156390  0.131722   0.159399\n",
       "2010-01-05  0.157238  0.158884  0.154995  0.202469   0.157092\n",
       "2010-01-06  0.156140  0.146049  0.153341  0.268184   0.143942\n",
       "2010-01-07  0.142436  0.134457  0.140094  0.432522   0.132105\n",
       "2010-01-08  0.127950  0.131464  0.134455  0.318492   0.138726"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_data(df):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    df['open'] = min_max_scaler.fit_transform(df.open.values.reshape(-1,1))\n",
    "    df['high'] = min_max_scaler.fit_transform(df.high.values.reshape(-1,1))\n",
    "    df['low'] = min_max_scaler.fit_transform(df.low.values.reshape(-1,1))\n",
    "    df['volume'] = min_max_scaler.fit_transform(df.volume.values.reshape(-1,1))\n",
    "    df['adj close'] = min_max_scaler.fit_transform(df['adj close'].values.reshape(-1,1))\n",
    "    return df\n",
    "df = normalize_data(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training set and Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(stock, seq_len):\n",
    "    amount_of_features = len(stock.columns) # 5\n",
    "    data = stock.as_matrix() \n",
    "    sequence_length = seq_len + 1 # index starting from 0\n",
    "    result = []\n",
    "    \n",
    "    for index in range(len(data) - sequence_length): # maxmimum date = lastest date - sequence length\n",
    "        result.append(data[index: index + sequence_length]) # index : index + 22days\n",
    "    \n",
    "    result = np.array(result)\n",
    "    row = round(0.9 * result.shape[0]) # 90% split\n",
    "    train = result[:int(row), :] # 90% date, all features \n",
    "    \n",
    "    x_train = train[:, :-1] \n",
    "    y_train = train[:, -1][:,-1]\n",
    "    \n",
    "    x_test = result[int(row):, :-1] \n",
    "    y_test = result[int(row):, -1][:,-1]\n",
    "\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], amount_of_features))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], amount_of_features))  \n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(layers):\n",
    "    d = 0.3\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(256, input_shape=(layers[1], layers[0]), return_sequences=True))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(LSTM(256, input_shape=(layers[1], layers[0]), return_sequences=False))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(Dense(32,kernel_initializer=\"uniform\",activation='relu'))        \n",
    "    model.add(Dense(1,kernel_initializer=\"uniform\",activation='linear'))\n",
    "    \n",
    "    # adam = keras.optimizers.Adam(decay=0.2)\n",
    "        \n",
    "    start = time.time()\n",
    "    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n",
    "    print(\"Compilation Time : \", time.time() - start)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.15704696 0.16116746 0.15638998 0.1317225  0.15939908]\n",
      " [0.15723843 0.15888449 0.15499506 0.20246902 0.15709185]\n",
      " [0.15613951 0.14604929 0.15334121 0.26818406 0.14394234]\n",
      " [0.14243617 0.13445699 0.14009362 0.43252209 0.13210528]\n",
      " [0.12795029 0.13146379 0.13445546 0.3184921  0.13872603]\n",
      " [0.13832355 0.1356323  0.13546617 0.48640628 0.1379653 ]\n",
      " [0.13265404 0.13052526 0.13020388 0.3271972  0.12907917]\n",
      " [0.11503787 0.1186032  0.12203482 0.43807453 0.12624527]\n",
      " [0.12120685 0.12613696 0.12689613 0.2858228  0.12855249]\n",
      " [0.12906589 0.12210374 0.12636158 0.36641044 0.12031836]\n",
      " [0.11895908 0.12062405 0.12373877 0.29099208 0.12668832]\n",
      " [0.12293853 0.11977851 0.12003013 0.21906583 0.12066114]\n",
      " [0.12082392 0.1172081  0.12073176 0.42532947 0.1228095 ]\n",
      " [0.10505596 0.0855935  0.10718348 0.45857351 0.09524822]\n",
      " [0.09014547 0.08614311 0.08987641 0.29795279 0.08688037]\n",
      " [0.08296912 0.08680264 0.08964255 0.29361033 0.08890336]\n",
      " [0.08571648 0.08597403 0.08801372 0.26721945 0.08863587]\n",
      " [0.08839717 0.08199153 0.08747078 0.21760714 0.08210705]\n",
      " [0.08340204 0.0777723  0.08245074 0.27910072 0.07847068]\n",
      " [0.08016357 0.08173786 0.07812399 0.15159969 0.0810454 ]\n",
      " [0.08046326 0.07946339 0.07741402 0.27611276 0.07945711]\n",
      " [0.07522667 0.07998762 0.08337794 0.20208586 0.08756581]\n",
      " [0.08216158 0.07773004 0.07995326 0.22763312 0.07582908]\n",
      " [0.0750019  0.07510891 0.07619447 0.2126765  0.07959922]\n",
      " [0.07841526 0.08277787 0.08329437 0.18152302 0.08142161]\n",
      " [0.08427619 0.08577107 0.08290183 0.18997604 0.0839044 ]\n",
      " [0.07972228 0.07953105 0.07977784 0.18018869 0.08224082]\n",
      " [0.0790979  0.08106145 0.08203312 0.16234157 0.08387095]\n",
      " [0.07880651 0.08190699 0.07924329 0.15354909 0.08112903]\n",
      " [0.08205335 0.08512004 0.08507355 0.2463037  0.08796707]\n",
      " [0.08632418 0.08791874 0.08446377 0.13668003 0.08538401]\n",
      " [0.08261118 0.08667583 0.08580859 0.15740756 0.08957211]\n",
      " [0.08510041 0.08968592 0.08499003 0.17199784 0.08751567]\n",
      " [0.09077817 0.09078513 0.08788845 0.14443059 0.08922104]\n",
      " [0.08715672 0.08342051 0.08465592 0.19355218 0.08275911]\n",
      " [0.07964736 0.08191544 0.08032078 0.15671183 0.07974969]\n",
      " [0.07393628 0.07302885 0.07200972 0.22301169 0.0755365 ]\n",
      " [0.07418605 0.07597135 0.07473277 0.13800092 0.07584583]\n",
      " [0.07566791 0.07957331 0.0760191  0.15072918 0.08076956]\n",
      " [0.08089618 0.08572036 0.08635153 0.29369771 0.08776647]\n",
      " [0.08662393 0.08930544 0.08840632 0.20817943 0.09132761]\n",
      " [0.09007055 0.09518188 0.09509695 0.2145486  0.0990769 ]\n",
      " [0.10243351 0.10676573 0.10473609 0.26370044 0.10711872]\n",
      " [0.10528905 0.10770426 0.10265623 0.16074844 0.10567255]\n",
      " [0.10118474 0.10389089 0.10222188 0.21406461 0.10375818]\n",
      " [0.10443989 0.10871893 0.1137822  0.38128304 0.11735074]\n",
      " [0.11318139 0.11885687 0.12022223 0.28536234 0.12127135]\n",
      " [0.12473676 0.12305071 0.12195126 0.18551258 0.11993385]\n",
      " [0.10687087 0.10346815 0.10622292 0.31374295 0.10625771]\n",
      " [0.10283312 0.10749286 0.10536255 0.23126305 0.10794633]\n",
      " [0.10821956 0.1104438  0.10789345 0.22384859 0.10824726]\n",
      " [0.10523911 0.10935308 0.10537928 0.11964292 0.10894945]\n",
      " [0.1013096  0.10455042 0.10501176 0.32320764 0.10359937]\n",
      " [0.09807107 0.10201384 0.10405115 0.26994861 0.10150949]\n",
      " [0.09884536 0.09163063 0.09691788 0.37092096 0.09440391]\n",
      " [0.08924633 0.08968592 0.09820421 0.44270268 0.10136737]\n",
      " [0.10049374 0.10571728 0.10835288 0.26496083 0.10600692]\n",
      " [0.10569697 0.10686721 0.10450224 0.18165074 0.10584811]\n",
      " [0.10380719 0.10733223 0.10227203 0.20920118 0.10564745]\n",
      " [0.10366565 0.10708705 0.10470268 0.13318455 0.10920859]] 0.10955136446292446\n"
     ]
    }
   ],
   "source": [
    "window = 60\n",
    "X_train, y_train, X_test, y_test = load_data(df, window)\n",
    "print (X_train[0], y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation Time :  0.04690408706665039\n"
     ]
    }
   ],
   "source": [
    "model = build_model([5,window,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1377 samples, validate on 154 samples\n",
      "Epoch 1/90\n",
      "1377/1377 [==============================] - 13s 10ms/step - loss: 0.1283 - acc: 7.2622e-04 - val_loss: 0.4212 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0527 - acc: 7.2622e-04 - val_loss: 0.0754 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0250 - acc: 7.2622e-04 - val_loss: 0.2231 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0263 - acc: 7.2622e-04 - val_loss: 0.1634 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0111 - acc: 7.2622e-04 - val_loss: 0.0467 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0113 - acc: 7.2622e-04 - val_loss: 0.0455 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0033 - acc: 7.2622e-04 - val_loss: 0.0708 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0054 - acc: 7.2622e-04 - val_loss: 0.0279 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0029 - acc: 7.2622e-04 - val_loss: 0.0112 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0030 - acc: 7.2622e-04 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "1377/1377 [==============================] - 11s 8ms/step - loss: 0.0025 - acc: 7.2622e-04 - val_loss: 0.0401 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "1377/1377 [==============================] - 11s 8ms/step - loss: 0.0019 - acc: 7.2622e-04 - val_loss: 0.0252 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "1377/1377 [==============================] - 11s 8ms/step - loss: 0.0020 - acc: 7.2622e-04 - val_loss: 0.0259 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0016 - acc: 7.2622e-04 - val_loss: 0.0371 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "1377/1377 [==============================] - 11s 8ms/step - loss: 0.0016 - acc: 7.2622e-04 - val_loss: 0.0357 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "1377/1377 [==============================] - 11s 8ms/step - loss: 0.0013 - acc: 7.2622e-04 - val_loss: 0.0249 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0016 - acc: 7.2622e-04 - val_loss: 0.0215 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "1377/1377 [==============================] - 11s 8ms/step - loss: 0.0013 - acc: 7.2622e-04 - val_loss: 0.0255 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "1377/1377 [==============================] - 11s 8ms/step - loss: 0.0014 - acc: 7.2622e-04 - val_loss: 0.0215 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0013 - acc: 7.2622e-04 - val_loss: 0.0147 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "1377/1377 [==============================] - 11s 8ms/step - loss: 0.0013 - acc: 7.2622e-04 - val_loss: 0.0171 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "1377/1377 [==============================] - 11s 8ms/step - loss: 0.0012 - acc: 7.2622e-04 - val_loss: 0.0170 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0012 - acc: 7.2622e-04 - val_loss: 0.0142 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "1377/1377 [==============================] - 10s 8ms/step - loss: 0.0012 - acc: 7.2622e-04 - val_loss: 0.0149 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "1377/1377 [==============================] - 10s 8ms/step - loss: 0.0011 - acc: 7.2622e-04 - val_loss: 0.0143 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "1377/1377 [==============================] - 11s 8ms/step - loss: 0.0012 - acc: 7.2622e-04 - val_loss: 0.0132 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "1377/1377 [==============================] - 11s 8ms/step - loss: 0.0011 - acc: 7.2622e-04 - val_loss: 0.0134 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0011 - acc: 7.2622e-04 - val_loss: 0.0126 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0011 - acc: 7.2622e-04 - val_loss: 0.0117 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "1377/1377 [==============================] - 11s 8ms/step - loss: 0.0011 - acc: 7.2622e-04 - val_loss: 0.0109 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "1377/1377 [==============================] - 11s 8ms/step - loss: 0.0011 - acc: 7.2622e-04 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0011 - acc: 7.2622e-04 - val_loss: 0.0101 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0011 - acc: 7.2622e-04 - val_loss: 0.0101 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0011 - acc: 7.2622e-04 - val_loss: 0.0097 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0011 - acc: 7.2622e-04 - val_loss: 0.0100 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0011 - acc: 7.2622e-04 - val_loss: 0.0090 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0010 - acc: 7.2622e-04 - val_loss: 0.0087 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0010 - acc: 7.2622e-04 - val_loss: 0.0096 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0011 - acc: 7.2622e-04 - val_loss: 0.0092 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0011 - acc: 7.2622e-04 - val_loss: 0.0086 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 9.9611e-04 - acc: 7.2622e-04 - val_loss: 0.0084 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0011 - acc: 7.2622e-04 - val_loss: 0.0098 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0010 - acc: 7.2622e-04 - val_loss: 0.0080 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0010 - acc: 7.2622e-04 - val_loss: 0.0081 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "1377/1377 [==============================] - 11s 8ms/step - loss: 9.6603e-04 - acc: 7.2622e-04 - val_loss: 0.0082 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 9.9448e-04 - acc: 7.2622e-04 - val_loss: 0.0075 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 9.9570e-04 - acc: 7.2622e-04 - val_loss: 0.0073 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 9.9518e-04 - acc: 7.2622e-04 - val_loss: 0.0069 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0010 - acc: 7.2622e-04 - val_loss: 0.0079 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 0.0010 - acc: 7.2622e-04 - val_loss: 0.0062 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 9.8121e-04 - acc: 7.2622e-04 - val_loss: 0.0074 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 9.8971e-04 - acc: 7.2622e-04 - val_loss: 0.0063 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 9.6180e-04 - acc: 7.2622e-04 - val_loss: 0.0063 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 9.4672e-04 - acc: 7.2622e-04 - val_loss: 0.0075 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 9.2182e-04 - acc: 7.2622e-04 - val_loss: 0.0059 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n",
      "1377/1377 [==============================] - 9s 7ms/step - loss: 9.7539e-04 - acc: 7.2622e-04 - val_loss: 0.0077 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "1377/1377 [==============================] - 11s 8ms/step - loss: 9.3564e-04 - acc: 7.2622e-04 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
      "Epoch 58/90\n",
      "1377/1377 [==============================] - 11s 8ms/step - loss: 9.4663e-04 - acc: 7.2622e-04 - val_loss: 0.0076 - val_acc: 0.0000e+00\n",
      "Epoch 59/90\n",
      "1377/1377 [==============================] - 10s 8ms/step - loss: 9.9381e-04 - acc: 7.2622e-04 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 60/90\n",
      "1377/1377 [==============================] - 11s 8ms/step - loss: 9.2577e-04 - acc: 7.2622e-04 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
      "Epoch 61/90\n",
      "1377/1377 [==============================] - 11s 8ms/step - loss: 9.1422e-04 - acc: 7.2622e-04 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
      "Epoch 62/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 9.0109e-04 - acc: 7.2622e-04 - val_loss: 0.0062 - val_acc: 0.0000e+00\n",
      "Epoch 63/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 9.2404e-04 - acc: 7.2622e-04 - val_loss: 0.0051 - val_acc: 0.0000e+00\n",
      "Epoch 64/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 9.0279e-04 - acc: 7.2622e-04 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Epoch 65/90\n",
      "1377/1377 [==============================] - 9s 7ms/step - loss: 9.3232e-04 - acc: 7.2622e-04 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 66/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 8.7610e-04 - acc: 7.2622e-04 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
      "Epoch 67/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 9.2868e-04 - acc: 7.2622e-04 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 68/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 8.9368e-04 - acc: 7.2622e-04 - val_loss: 0.0059 - val_acc: 0.0000e+00\n",
      "Epoch 69/90\n",
      "1377/1377 [==============================] - 11s 8ms/step - loss: 8.7246e-04 - acc: 7.2622e-04 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 70/90\n",
      "1377/1377 [==============================] - 12s 8ms/step - loss: 9.0869e-04 - acc: 7.2622e-04 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
      "Epoch 71/90\n",
      "1377/1377 [==============================] - 11s 8ms/step - loss: 8.8025e-04 - acc: 7.2622e-04 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 72/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 8.4041e-04 - acc: 7.2622e-04 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
      "Epoch 73/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 9.3303e-04 - acc: 7.2622e-04 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 74/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 9.3788e-04 - acc: 7.2622e-04 - val_loss: 0.0062 - val_acc: 0.0000e+00\n",
      "Epoch 75/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 8.9841e-04 - acc: 7.2622e-04 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 76/90\n",
      "1377/1377 [==============================] - 11s 8ms/step - loss: 8.5722e-04 - acc: 7.2622e-04 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 77/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 8.7782e-04 - acc: 7.2622e-04 - val_loss: 0.0051 - val_acc: 0.0000e+00\n",
      "Epoch 78/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 8.2648e-04 - acc: 7.2622e-04 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 79/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 8.7818e-04 - acc: 7.2622e-04 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
      "Epoch 80/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 8.1637e-04 - acc: 7.2622e-04 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 81/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 8.0024e-04 - acc: 7.2622e-04 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 82/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 8.5780e-04 - acc: 7.2622e-04 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
      "Epoch 83/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 8.1977e-04 - acc: 7.2622e-04 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
      "Epoch 84/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 8.1116e-04 - acc: 7.2622e-04 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
      "Epoch 85/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 8.2667e-04 - acc: 7.2622e-04 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 86/90\n",
      "1377/1377 [==============================] - 10s 8ms/step - loss: 8.8033e-04 - acc: 7.2622e-04 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
      "Epoch 87/90\n",
      "1377/1377 [==============================] - 10s 8ms/step - loss: 9.0017e-04 - acc: 7.2622e-04 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 88/90\n",
      "1377/1377 [==============================] - 10s 8ms/step - loss: 8.2809e-04 - acc: 7.2622e-04 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
      "Epoch 89/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 8.5015e-04 - acc: 7.2622e-04 - val_loss: 0.0058 - val_acc: 0.0000e+00\n",
      "Epoch 90/90\n",
      "1377/1377 [==============================] - 10s 7ms/step - loss: 8.7209e-04 - acc: 7.2622e-04 - val_loss: 0.0045 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24f076794a8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=512,epochs=90,validation_split=0.1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170, 1)\n"
     ]
    }
   ],
   "source": [
    "# print(X_test[-1])\n",
    "diff=[]\n",
    "ratio=[]\n",
    "p = model.predict(X_test)\n",
    "print (p.shape)\n",
    "# for each data index in test data\n",
    "for u in range(len(y_test)):\n",
    "    # pr = prediction day u\n",
    "    pr = p[u][0]\n",
    "    # (y_test day u / pr) - 1\n",
    "    ratio.append((y_test[u]/pr)-1)\n",
    "    diff.append(abs(y_test[u]- pr))\n",
    "    # print(u, y_test[u], pr, (y_test[u]/pr)-1, abs(y_test[u]- pr))\n",
    "    # Last day prediction\n",
    "    # print(p[-1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denormalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"prices-split-adjusted.csv\", index_col = 0)\n",
    "df[\"adj close\"] = df.close # Moving close to the last column\n",
    "df.drop(['close'], 1, inplace=True) # Moving close to the last column\n",
    "df = df[df.symbol == 'GOOG']\n",
    "df.drop(['symbol'],1,inplace=True)\n",
    "\n",
    "# Bug fixed at here, please update the denormalize function to this one\n",
    "def denormalize(df, normalized_value): \n",
    "    df = df['adj close'].values.reshape(-1,1)\n",
    "    normalized_value = normalized_value.reshape(-1,1)\n",
    "    \n",
    "    #return df.shape, p.shape\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    a = min_max_scaler.fit_transform(df)\n",
    "    new = min_max_scaler.inverse_transform(normalized_value)\n",
    "    return new\n",
    "\n",
    "newp = denormalize(df, p)\n",
    "newy_test = denormalize(df, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.00092 MSE (0.03 RMSE)\n",
      "Test Score: 0.00717 MSE (0.08 RMSE)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0009182837212629797, 0.0071659540757536885)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_score(model, X_train, y_train, X_test, y_test):\n",
    "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Train Score: %.5f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Score: %.5f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "    return trainScore[0], testScore[0]\n",
    "\n",
    "\n",
    "model_score(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt2\n",
    "\n",
    "plt2.plot(newp,color='red', label='Prediction')\n",
    "plt2.plot(newy_test,color='blue', label='Actual')\n",
    "plt2.legend(loc='best')\n",
    "plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
